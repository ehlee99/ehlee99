import tensorflow as tf
import numpy as np
tf.__version__
!nvidia-smi -L
RANDOM_SEED: int = 42
import random
import os
os.environ['PYTHONHASHSEED']= str(RANDOM_SEED)
random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)
tf.experimental.numpy.random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
!pip install split-folders[full]
import splitfolders

splitfolders.ratio("/content/data", output="dataset_splitted",
    seed=RANDOM_SEED, ratio=(0.9, 0.1,), group_prefix=None, move=False)
DATASET_DIR: str = "/content/data"
import os
for dirpath, dirnames, filenames in os.walk(DATASET_DIR):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
import pathlib
data_dir = pathlib.Path("/content/dataset_splitted/train")
class_names = np.array(sorted([item.name for item in data_dir.glob("*")])).tolist() # created a list of class_names from the subdirector
class_names
import os
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# í´ëž˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì´ ë³€ìˆ˜ëŠ” ì •ì˜ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤)
class_names = ['green_area', 'cloudy' ,'desert' ,'water']  # í•„ìš”ì— ë”°ë¼ ë‹¤ë¥¸ í´ëž˜ìŠ¤ ì´ë¦„ì„ ì¶”ê°€

# ëžœë¤ìœ¼ë¡œ í´ëž˜ìŠ¤ ì´ë¦„ ì„ íƒ
target_class = random.choice(class_names)

# íƒ€ê²Ÿ í´ë” ê²½ë¡œ êµ¬ì„±
target_folder = os.path.join("/content/dataset_splitted/train", target_class)

# íƒ€ê²Ÿ í´ë”ê°€ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸
if os.path.exists(target_folder) and os.path.isdir(target_folder):
    # íƒ€ê²Ÿ í´ë”ì—ì„œ ëžœë¤ ì´ë¯¸ì§€ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    random_image = random.choice(os.listdir(target_folder))

    # ì´ë¯¸ì§€ë¥¼ ì½ì–´ matplotlibë¡œ ì¶œë ¥
    img_path = os.path.join(target_folder, random_image)
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.title(target_class)
    plt.show()

    print(f"Image shape: {img.shape}")
else:
    print(f"Folder {target_folder} does not exist.")
BATCH_SIZE: int = 32
EPOCHS: int = 5
AUGMENTATION_FACTOR: float = 0.2
LABEL_MODE: str = "categorical"
IMAGE_SIZE = (256, 256)

TRAIN_DIR: str = "dataset_splitted/train"
TEST_DIR: str = "dataset_splitted/val"
print("Training set ðŸ§ ")
train_data = tf.keras.preprocessing.image_dataset_from_directory(
    directory=TRAIN_DIR,
    image_size=IMAGE_SIZE,
    label_mode=LABEL_MODE,
    batch_size=BATCH_SIZE,
    seed=RANDOM_SEED,
    shuffle=True
)

print("Test set ðŸ§ ")
test_data = tf.keras.preprocessing.image_dataset_from_directory(
    directory=TEST_DIR,
    image_size=IMAGE_SIZE,
    label_mode=LABEL_MODE,
    batch_size=BATCH_SIZE,
    seed=RANDOM_SEED,
    shuffle=False
)
class_names = train_data.class_names
class_names
from tensorflow.keras.layers import Dense, Input, RandomRotation, RandomFlip, RandomZoom, RandomHeight, RandomWidth, Rescaling, GlobalAveragePooling2D
from tensorflow.keras import Sequential

augmentation_layer = Sequential([
    RandomFlip("horizontal", seed=RANDOM_SEED),
    RandomRotation(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    RandomZoom(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    RandomHeight(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    RandomWidth(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    Rescaling(1/255.)
], name="augmentation_layer")

augmentation_layer
target_dir = "/content/dataset_splitted/train"
target_class = random.choice(class_names)
target_dir = f"{target_dir}/{target_class}"
random_image = random.choice(os.listdir(target_dir))
random_image_path = target_dir + "/" + random_image

print(random_image_path)
# Read in the random image
img = mpimg.imread(random_image_path)
plt.title(f"Origininal random image from class: {target_class}")
# plt.axis(False)
plt.imshow(img);

# Now lets plot our augmented random image
augmented_image = augmentation_layer(img, training=True)
plt.figure()
plt.title(f"augmented random image from class: {target_class}")
plt.imshow(augmented_image)
# Turn off all warnings except for errors
tf.get_logger().setLevel('ERROR')

# set seed
tf.random.set_seed(RANDOM_SEED)

base_model = tf.keras.applications.ResNet50V2(include_top=False)
base_model.trainable = False
input_layer = Input(shape=IMAGE_SIZE + (3, ), name="input_layer")
x = augmentation_layer(input_layer)
x = base_model(x, training=False)
x = GlobalAveragePooling2D(name="global_average_pooling2D")(x)
ouptut_layer = Dense(len(class_names), activation=tf.keras.activations.sigmoid, name="output_layer")(x)

model_1 = tf.keras.Model(input_layer, ouptut_layer)
# compile the model
model_1.compile(
    loss=tf.keras.losses.CategoricalCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(),
    metrics=["accuracy"]
)
model_1.summary()
import datetime

def create_tensorboard_callback(dir_name, experiment_name):
    log_dir = dir_name + "/" + experiment_name + "/" + \
        datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=log_dir
    )
    print(f"Saving TensorBoard log files to: {log_dir}")
    return tensorboard_callback
history_1 = model_1.fit(
    train_data,
    epochs=EPOCHS,
    validation_data=test_data,
    steps_per_epoch=len(train_data),
    validation_steps=int(0.15 * len(test_data)),
    callbacks=[
        create_tensorboard_callback(dir_name="tensorboard", experiment_name="model_1")
    ]
)
loss = history_1.history['loss']
val_loss = history_1.history['val_loss']

accuracy = history_1.history["accuracy"]
val_accuracy = history_1.history["val_accuracy"]

epochs = range(len(history_1.history['loss']))

# Plot loss
plt.plot(epochs, loss, label='training_loss')
plt.plot(epochs, val_loss, label='val_loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.legend()

# Plot accuracy
plt.figure()
plt.plot(epochs, accuracy, label='training_accuracy')
plt.plot(epochs, val_accuracy, label='val_accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.legend()
evaluation_1 = model_1.evaluate(test_data)
evaluation_1
preds_probs = model_1.predict(test_data)
preds_probs[:10]
pred_classes = preds_probs.argmax(axis=1)
pred_classes[:10]
y_labels = []
for images, labels in test_data.unbatch():
    y_labels.append(labels.numpy().argmax())
y_labels[:10]
from sklearn.metrics import accuracy_score
sklearn_accuracy = accuracy_score(y_true=y_labels,
                                  y_pred=pred_classes)
sklearn_accuracy
from sklearn.metrics import confusion_matrix
import itertools
import matplotlib.pyplot as plt

def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):
    """Makes a labelled confusion matrix comparing predictions and ground truth labels.

    If classes is passed, confusion matrix will be labelled, if not, integer class values
    will be used.

    Args:
      y_true: Array of truth labels (must be same shape as y_pred).
      y_pred: Array of predicted labels (must be same shape as y_true).
      classes: Array of class labels (e.g. string form). If `None`, integer labels are used.
      figsize: Size of output figure (default=(10, 10)).
      text_size: Size of output figure text (default=15).
      norm: normalize values or not (default=False).
      savefig: save confusion matrix to file (default=False).

    Returns:
      A labelled confusion matrix plot comparing y_true and y_pred.

    Example usage:
      make_confusion_matrix(y_true=test_labels, # ground truth test labels
                            y_pred=y_preds, # predicted labels
                            classes=class_names, # array of class label names
                            figsize=(15, 15),
                            text_size=10)
    """
    # Create the confustion matrix
    plt.rcParams.update({"font.size": text_size})
    cm = confusion_matrix(y_true, y_pred)
    cm_norm = cm.astype("float") / \
        cm.sum(axis=1)[:, np.newaxis]  # normalize it
    n_classes = cm.shape[0]  # find the number of classes we're dealing with
    # Plot the figure and make it pretty
    fig, ax = plt.subplots(figsize=figsize)
    # colors will represent how 'correct' a class is, darker == better
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    # Are there a list of classes?
    if classes:
        labels = classes
    else:
        labels = np.arange(cm.shape[0])

    # Label the axes
    ax.set(title="Confusion Matrix",
           xlabel="Predicted label",
           ylabel="True label",
           # create enough axis slots for each class
           xticks=np.arange(n_classes),
           yticks=np.arange(n_classes),
           # axes will labeled with class names (if they exist) or ints
           xticklabels=labels,
           yticklabels=labels)

    # Make x-axis labels appear on bottom
    ax.xaxis.set_label_position("bottom")
    ax.xaxis.tick_bottom()

    # Set the threshold for different colors
    threshold = (cm.max() + cm.min()) / 2.

    # Plot the text on each cell
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if norm:
            plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",
                     horizontalalignment="center",
                     color="white" if cm[i, j] > threshold else "black",
                     size=text_size)
        else:
            plt.text(j, i, f"{cm[i, j]}",
                     horizontalalignment="center",
                     color="white" if cm[i, j] > threshold else "black",
                     size=text_size)

    # Save the figure to the current working directory
    if savefig:
        fig.savefig("confusion_matrix.png")

make_confusion_matrix(y_true=y_labels,
                      y_pred=pred_classes,
                      classes=class_names,
                      figsize=(8, 8))
from sklearn.metrics import classification_report
print(classification_report(y_true=y_labels,
                            y_pred=pred_classes))
